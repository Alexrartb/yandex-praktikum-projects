{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.str.lower()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "tokenizer = RegexpTokenizer(r'\\w{2,}')\n",
    "def preprocessing(text):\n",
    "    new_words = tokenizer.tokenize(text)\n",
    "    new_list = []\n",
    "    for w in new_words:\n",
    "        w = stemmer.stem(w)\n",
    "        new_list.append(w)\n",
    "    new_list = ' '.join(new_list)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b592474fb4e147e1bba24f65fc5725aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = pd.Series([preprocessing(text) for text in notebook.tqdm(df['text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Александра\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size (39893, 153357)\n",
      "train size (119678, 153357)\n"
     ]
    }
   ],
   "source": [
    "features = tf_idf\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(tf_idf, target, test_size = 0.25, random_state = 12345) \n",
    "\n",
    "\n",
    "print('test size', features_test.shape)\n",
    "print('train size', features_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  5 F1: 0.6550218340611353\n",
      "n_estimators:  10 F1: 0.6470868391808223\n",
      "n_estimators:  15 F1: 0.6822588090475459\n",
      "n_estimators:  20 F1: 0.6605533596837944\n",
      "n_estimators:  25 F1: 0.6825568797399783\n",
      "n_estimators:  30 F1: 0.6703262233375157\n",
      "n_estimators:  35 F1: 0.6879137798306388\n",
      "n_estimators:  40 F1: 0.6832143965249767\n",
      "n_estimators:  45 F1: 0.6890704485894866\n",
      "n_estimators:  50 F1: 0.6783151326053043\n",
      "Wall time: 1h 24min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n_estimators in range(5,51,5):\n",
    "    model =  RandomForestClassifier(n_estimators = n_estimators, random_state = 123)\n",
    "    model.fit(features_train, target_train)\n",
    "    print('n_estimators: ', n_estimators,'F1:',f1_score(target_test, model.predict(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927219572241883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     35806\n",
      "           1       0.93      0.55      0.69      4087\n",
      "\n",
      "    accuracy                           0.95     39893\n",
      "   macro avg       0.94      0.77      0.83     39893\n",
      "weighted avg       0.95      0.95      0.94     39893\n",
      "\n",
      "Wall time: 32min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model =  RandomForestClassifier()\n",
    "\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    " \n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "print(f1_score(target_test, predictions))\n",
    "print(metrics.classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748544317446625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     35806\n",
      "           1       0.67      0.85      0.75      4087\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.83      0.90      0.86     39893\n",
      "weighted avg       0.95      0.94      0.94     39893\n",
      "\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SGDClassifier(class_weight = 'balanced')\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "print(f1_score(target_test, predictions))\n",
    "print(metrics.classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75564681724846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     35806\n",
      "           1       0.68      0.86      0.76      4087\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.83      0.90      0.86     39893\n",
      "weighted avg       0.95      0.94      0.95     39893\n",
      "\n",
      "Wall time: 5.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(class_weight = 'balanced', random_state = 123)\n",
    "\n",
    "model = model.fit(features_train, target_train)\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "print(f1_score(target_test, predictions))\n",
    "print(metrics.classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 F1 score:  0.5472055030094584\n",
      "depth:  10 F1 score:  0.6249404289118348\n",
      "depth:  15 F1 score:  0.6534012031466914\n",
      "depth:  20 F1 score:  0.6762633078422552\n",
      "depth:  25 F1 score:  0.684070796460177\n",
      "depth:  30 F1 score:  0.6951183864367143\n",
      "depth:  35 F1 score:  0.7023826714801445\n",
      "depth:  40 F1 score:  0.7048899056334\n",
      "depth:  45 F1 score:  0.7089678510998307\n",
      "depth:  50 F1 score:  0.7099916504313942\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for depth in range(5,51,5):\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_test)\n",
    "    print('depth: ',depth,'F1 score: ',f1_score(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27751734483405216\n",
      "0.20727193555410406\n",
      "0.1845132743362832\n",
      "0.15044047887960244\n",
      "0.139122527847238\n",
      "0.27355110642781877\n",
      "0.43489780469341416\n",
      "0.46655549379284783\n",
      "0.5076233183856501\n",
      "0.5130403715612719\n"
     ]
    }
   ],
   "source": [
    "for n in range(5,51,5):\n",
    "    model = KNeighborsClassifier(n_neighbors = n)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_test)\n",
    "    print(f1_score(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Лучший результат показала модель логистической регрессии - ~0.76\n",
    "2. Самые плохие результаты у классификатора с методом k-ближайшего соседа, хотя прогоняя код в GoogleColab, результатыы были порядком выше\n",
    "3. Также хороший результат у SGDClassifier: 0.748544317446625, если округлить до сотых, то результат подходит под условие задачи (0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
